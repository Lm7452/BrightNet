{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Modules and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available(): \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data Loaders\n",
    "##### Ensure That WildCam_3classes is in the correct location\n",
    "##### Run Brightness_subset_maker.ipynb to create \"brightest\" image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WildCamDataset(Dataset):\n",
    "    def __init__(self, img_paths, annotations, transform=T.ToTensor(), directory='WildCam_3classes/train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "        self.dir = directory\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ID = '{}/{}'.format(self.dir, self.img_paths[index])\n",
    "        img = Image.open(ID).convert('RGB')\n",
    "        X = self.transform(img)             \n",
    "        y = self.annotations['labels'][self.img_paths[index]]\n",
    "        loc = self.annotations['locations'][self.img_paths[index]]\n",
    "        return X, y, loc\n",
    "    \n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "transform = T.Compose([\n",
    "            T.Resize((112,112)),\n",
    "            T.ToTensor(),\n",
    "            normalize\n",
    "])\n",
    "\n",
    "param_train = {\n",
    "    'batch_size': 256,       \n",
    "    'shuffle': True\n",
    "    }\n",
    "\n",
    "param_valtest = {\n",
    "    'batch_size': 256,\n",
    "    'shuffle': False\n",
    "    }\n",
    "\n",
    "annotations = json.load(open('WildCam_3classes/annotations.json'))\n",
    "\n",
    "train_images = sorted(os.listdir('WildCam_3classes/train'))\n",
    "train_dset = WildCamDataset(train_images, annotations, transform, directory='WildCam_3classes/train')\n",
    "train_loader = DataLoader(train_dset, **param_train)\n",
    "\n",
    "val_images = sorted(os.listdir('WildCam_3classes/val'))\n",
    "val_dset = WildCamDataset(val_images, annotations, transform, directory=\"WildCam_3classes/val\")\n",
    "val_loader = DataLoader(val_dset, **param_valtest)\n",
    "\n",
    "test_images = sorted(os.listdir('WildCam_3classes/test'))\n",
    "test_dset = WildCamDataset(test_images, annotations, transform, directory=\"WildCam_3classes/test\")\n",
    "test_loader = DataLoader(test_dset, **param_valtest)\n",
    "\n",
    "brightest_labels = json.load(open('WildCam_3classes/brightest_labels.json'))\n",
    "\n",
    "bright_images = sorted(os.listdir('WildCam_3classes/brightest'))\n",
    "bright_dset = WildCamDataset(bright_images, brightest_labels, transform, directory=\"WildCam_3classes/brightest\")\n",
    "bright_loader = DataLoader(bright_dset, **param_valtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ResNet+ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "channel_1 = 64\n",
    "channel_2 = 128\n",
    "channel_3 = 256\n",
    "hidden_layer_1 = 256\n",
    "hidden_layer_2 = 128\n",
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "dropout_rate = 0.4\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, use_se=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        self.use_se = use_se\n",
    "        if self.use_se:\n",
    "            self.se_block = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.use_se:\n",
    "            out = self.se_block(out)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, channels, _, _ = x.size()\n",
    "        y = x.mean((2, 3))  \n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(batch, channels, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "class BrightResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(BrightResNet18, self).__init__()\n",
    "        self.in_channels = 64  \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=2, padding=4, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2, use_se=True)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2, use_se=True)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1, use_se=False):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample, use_se=use_se))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, use_se=use_se))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = BrightResNet18(3)  \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Training\n",
    "##### Same Across all 3 models\n",
    "##### If models stored locally, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader_train, epochs=5, print_every=1):\n",
    "    iteration_loss = []  \n",
    "    model = model.to(device=device)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y, _) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = criterion(scores, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iteration_loss.append(loss.item())  # Track loss for each iteration\n",
    "            if t % print_every == 0:\n",
    "                print(f\"Epoch {e}, Iteration {t}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "        print(f\"Epoch {e} complete.\")\n",
    "    \n",
    "    # Plot training loss per iteration\n",
    "    plt.plot(iteration_loss, label='Training Loss (Pretrained)')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Across Iterations (Pretrained Model)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, train_loader, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'resnet_plus.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmorr\\AppData\\Local\\Temp\\ipykernel_23772\\2271317145.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet_plus_loaded = torch.load('resnet_plus.pth')\n"
     ]
    }
   ],
   "source": [
    "resnet_plus_loaded = torch.load('resnet_plus.pth')\n",
    "resnet_plus_loaded = resnet_plus_loaded.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Classification Report and Confusion Matrix for Model on each data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()  \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in loader:  \n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "\n",
    "            y_true.extend(y.cpu().numpy()) \n",
    "            y_pred.extend(preds.cpu().numpy())  \n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Rabbit', 'Bobcat', 'Cat']))\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ResNet+ Test Set Evaluation:\")\n",
    "y_true_custom, y_pred_custom = evaluate(resnet_plus_loaded, test_loader, device)\n",
    "\n",
    "print(\"ResNet+ Validation Set Evaluation:\")\n",
    "y_true_custom, y_pred_custom = evaluate(resnet_plus_loaded, val_loader, device)\n",
    "\n",
    "print(\"ResNet+ Bright Set Evaluation:\")\n",
    "y_true_custom, y_pred_custom = evaluate(resnet_plus_loaded, bright_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_and_confusion_matrix(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    class_names = [\"rabbit\", \"bobcat\", \"cat\"]\n",
    "    num_classes = len(class_names)\n",
    "    class_correct = np.zeros(num_classes)  \n",
    "    class_samples = np.zeros(num_classes)  \n",
    "\n",
    "    model.eval()  \n",
    "    with torch.no_grad(): \n",
    "        for x, y, _ in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            \n",
    "            num_correct += (preds == y).sum().item()\n",
    "            num_samples += preds.size(0)\n",
    "            \n",
    "            for i in range(num_classes):\n",
    "                class_correct[i] += ((preds == y) & (y == i)).sum().item()\n",
    "                class_samples[i] += (y == i).sum().item()\n",
    "\n",
    "    overall_acc = float(num_correct) / num_samples\n",
    "    print(f'Overall accuracy: {num_correct} / {num_samples} ({100 * overall_acc:.2f}%)')\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        if class_samples[i] > 0:\n",
    "            class_acc = float(class_correct[i]) / class_samples[i]\n",
    "            print(f'Accuracy for class {i} ({class_names[i]}): {class_correct[i]} / {class_samples[i]} ({100 * class_acc:.2f}%)')\n",
    "        else:\n",
    "            print(f'No samples for class {i} ({class_names[i]})')\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ResNet+ Test Set Confusion Matrix\")\n",
    "check_accuracy_and_confusion_matrix(test_loader, resnet_plus_loaded)\n",
    "\n",
    "print(\"ResNet+ Validation Set Confusion Matrix\")\n",
    "check_accuracy_and_confusion_matrix(val_loader, resnet_plus_loaded)\n",
    "\n",
    "print(\"ResNet+ Bright Set Confusion Matrix\")\n",
    "check_accuracy_and_confusion_matrix(bright_loader, resnet_plus_loaded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
